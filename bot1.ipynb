{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bot1\n",
    "\n",
    "create the first bot\n",
    "\n",
    "we are at feat/chatbotv1 now.\n",
    "\n",
    "HaHa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, PromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(data_path):\n",
    "   with open(data_path) as f:\n",
    "       data = json.load(f)\n",
    "   return data\n",
    "info_path = '.env/configs.json'\n",
    "info = read_json(info_path)\n",
    "os.environ['GOOGLE_API_KEY'] = info['g_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functional programing\n",
    "def llm_generation(sys_msg, text):\n",
    "    chat_template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=(sys_msg)\n",
    "            ),\n",
    "            HumanMessagePromptTemplate.from_template(text)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-pro\",\n",
    "        temperature=0.5,\n",
    "        convert_system_message_to_human=True\n",
    "    )\n",
    "\n",
    "    chain = chat_template | llm\n",
    "\n",
    "    input_data = {\n",
    "        \"text\" : text\n",
    "    }\n",
    "\n",
    "    response = chain.invoke(input_data)\n",
    "\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\weichung.chen\\AppData\\Local\\miniconda3\\envs\\WeichungRepository\\lib\\site-packages\\langchain_google_genai\\chat_models.py:352: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'明天是星期三'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys_msg=\"You are a helpful assistant to translate. If you receive a Chinese sentence, then translate to English. If you receive a English sentence , then translate to Chinese.\"\n",
    "text = \"Tomorrow is Wednesday\"\n",
    "llm_generation(sys_msg, text)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
